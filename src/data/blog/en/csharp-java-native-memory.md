---
author: Ulala-X
pubDatetime: 2025-12-23T00:00:00+09:00
title: C# vs Java Native Memory Handling - The Decisive Difference Between Pin and Copy
slug: csharp-java-native-memory
featured: true
draft: false
lang: en
lang_ref: csharp-java-native-memory
tags:
  - csharp
  - java
  - native-memory
  - performance
  - benchmark
description: Comparing C#'s Zero-copy Pinning with Java's Mandatory Copy Mechanism
---

# C# vs Java Native Memory Handling - The Decisive Difference Between Pin and Copy

> Comparing C#'s Zero-copy Pinning with Java's Mandatory Copy Mechanism

**December 23, 2025**

---

## Why This Difference Matters

When communicating with native libraries or handling high-performance I/O, data transfer between managed memory and native memory is unavoidable. C# and Java use fundamentally different mechanisms:

- **C#**: Can pass managed arrays to native code via Zero-copy using the `fixed` keyword
- **Java**: No pinning capability - Heap â†’ Native copying is mandatory

This difference directly impacts performance when frequently processing large volumes of data. This article provides a concrete comparison of memory handling approaches in both languages through benchmark data.

---

## Chapter 1: C# Native Memory Handling

C# provides several methods for handling native memory. Let's examine the performance characteristics of each through benchmarks.

### 1.1 Native Memory Allocation Methods

**Test Environment**:
- CPU: Intel Core Ultra 7 265K (20 cores)
- OS: Ubuntu 24.04.3 LTS
- Runtime: .NET 8.0.22
- BenchmarkDotNet v0.14.0

> **Time Unit Reference**
> - **Î¼s (microsecond)**: 1Î¼s = 0.000001 sec = 1/1,000,000 sec
> - **ns (nanosecond)**: 1ns = 0.000000001 sec = 1/1,000,000,000 sec
> - Note: 1ms (millisecond) = 1,000Î¼s = 1,000,000ns

| Method | 64B | 1KB | 64KB | 1MB |
|--------|-----|-----|------|-----|
| StackAlloc | 11.7 Î¼s | 12.1 Î¼s | 30.0 Î¼s | 106.1 Î¼s |
| NativeMemory.Alloc | 63.6 Î¼s | 61.5 Î¼s | 61.2 Î¼s | 61.4 Î¼s |
| Marshal.AllocHGlobal | 74.3 Î¼s | 72.6 Î¼s | 82.8 Î¼s | 86.3 Î¼s |

**Key Insights**:

1. **StackAlloc** is fastest at 64B with 11.7 Î¼s, but performance degrades as size increases (106.1 Î¼s at 1MB).
2. **NativeMemory.Alloc** shows consistent performance regardless of size (approximately 61-63 Î¼s). This demonstrates the stability of heap allocation mechanisms.
3. **Marshal.AllocHGlobal** is a legacy API and slowest across all sizes.

**Practical Guide**: Use StackAlloc for small sizes that can be safely allocated on the stack (< 1KB), otherwise use NativeMemory.Alloc.

**Specific usage examples for each allocation method**:

```csharp
// 1. StackAlloc - Allocate on stack memory
unsafe
{
    byte* buffer = stackalloc byte[1024];
    // Automatically freed when function exits
}

// 2. NativeMemory.Alloc - Allocate on native heap (.NET 6+)
unsafe
{
    byte* buffer = (byte*)NativeMemory.Alloc(1024);
    try {
        // Use
    } finally {
        NativeMemory.Free(buffer);
    }
}

// 3. Marshal.AllocHGlobal - Allocate on native heap (legacy)
IntPtr buffer = Marshal.AllocHGlobal(1024);
try {
    // Use
} finally {
    Marshal.FreeHGlobal(buffer);
}
```

**Memory allocation method characteristics comparison**:

| Method | Location | GC Managed | Deallocation | Characteristics |
|--------|----------|------------|--------------|-----------------|
| `stackalloc` | Stack | âŒ | Automatic (scope exit) | Fastest, size limited (max ~1MB, recommended < 1KB) |
| `NativeMemory.Alloc` | Native Heap | âŒ | Manual (`Free`) | Consistent performance, modern API |
| `Marshal.AllocHGlobal` | Native Heap | âŒ | Manual (`FreeHGlobal`) | Legacy, P/Invoke compatible |
| `new byte[]` | Managed Heap | âœ… | GC | Safest, GC overhead |

**C# process memory structure**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Process Memory                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Stack         â”‚  Managed Heap   â”‚     Native Heap         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ stackalloc    â”‚ â€¢ new byte[]    â”‚ â€¢ NativeMemory.Alloc    â”‚
â”‚ â€¢ Local vars    â”‚ â€¢ GC managed    â”‚ â€¢ Marshal.AllocHGlobal  â”‚
â”‚ â€¢ Auto freed    â”‚ â€¢ Auto freed    â”‚ â€¢ Manual free required  â”‚
â”‚ â€¢ ~1MB limit    â”‚ â€¢ No size limit â”‚ â€¢ No size limit         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 C#'s Core Strength: Zero-copy Pinning

C#'s most powerful feature is Zero-copy transfer using the `fixed` keyword.

```csharp
byte[] managedArray = new byte[1024];

// Pin with fixed to prevent GC from moving memory
unsafe
{
    fixed (byte* ptr = managedArray)
    {
        // Pass pointer to native code without copying
        NativeLibrary.ProcessData(ptr, managedArray.Length);
    }
}
// Automatically unpinned when exiting fixed block
```

**Pinning Benchmark** (10,000 iterations):

| Method | 64B | 1KB | 64KB | 1MB |
|--------|-----|-----|------|-----|
| Fixed (pin only) | 5.8 Î¼s | 5.8 Î¼s | 26.4 Î¼s | 28.9 Î¼s |
| GCHandle.Pinned | 245.4 Î¼s | 245.5 Î¼s | 260.5 Î¼s | 259.8 Î¼s |
| MemoryMarshal (Span) | 4.2 Î¼s | 4.3 Î¼s | 4.5 Î¼s | 4.6 Î¼s |

**Key Insights**:

1. **MemoryMarshal.GetReference** with Span is fastest across all sizes at approximately 4.2-4.6 Î¼s.
2. **fixed** keyword shows respectable performance at 5.8 Î¼s for 64B~1KB.
3. **GCHandle.Pinned** is significantly slower at 245 Î¼s. Explicit allocation/deallocation overhead is substantial.

### 1.3 Managed â†’ Native Data Transfer Performance

We compared methods for transferring data from managed arrays to native memory.

**Benchmark Results** (10,000 iterations):

| Method | 64B | 1KB | 64KB | 1MB |
|--------|-----|-----|------|-----|
| Marshal.Copy | 11.2 Î¼s | 13.8 Î¼s | 106.1 Î¼s | 1,330 Î¼s |
| Buffer.MemoryCopy (fixed) | 12.7 Î¼s | 16.1 Î¼s | 176.1 Î¼s | 2,146 Î¼s |
| Span.CopyTo (native) | 11.2 Î¼s | 15.8 Î¼s | 166.4 Î¼s | 2,104 Î¼s |

**Key Insights**:

1. **For small sizes (64B)**, all methods are similar (approximately 11-13 Î¼s).
2. **For 1MB data**, Marshal.Copy is fastest at 1,330 Î¼s, while Buffer.MemoryCopy is 1.6Ã— slower at 2,146 Î¼s.
3. **If copying is necessary**, Marshal.Copy is the fastest. However, for read-only operations, pinning with fixed for zero-copy transfer as shown in Section 1.2 is optimal.

**Specific usage for each copy method**:

```csharp
byte[] managedArray = new byte[1024];
IntPtr nativePtr = Marshal.AllocHGlobal(1024);

// 1. Marshal.Copy - Managed â†’ Native copy
Marshal.Copy(managedArray, 0, nativePtr, 1024);

// 2. Buffer.MemoryCopy - Copy after pinning with fixed
unsafe
{
    fixed (byte* src = managedArray)
    {
        Buffer.MemoryCopy(src, (void*)nativePtr, 1024, 1024);
    }
}

// 3. Span.CopyTo - Span-based copy
unsafe
{
    Span<byte> nativeSpan = new Span<byte>((void*)nativePtr, 1024);
    managedArray.AsSpan().CopyTo(nativeSpan);
}
```

**Internal operation comparison for copy methods**:

| Method | Internal Operation | Pinning Required | Advantages | Disadvantages |
|--------|-------------------|------------------|------------|---------------|
| `Marshal.Copy` | Internally pin + memcpy | Automatic | Fastest, simple, no unsafe needed | Requires IntPtr |
| `Buffer.MemoryCopy` | Direct memcpy call | Manual (fixed) | Flexible, direct pointer control | Requires unsafe block |
| `Span.CopyTo` | Internally memmove | Manual (fixed) | Modern API, type-safe | Slightly slower |

**Memory usage pattern comparison between copy and zero-copy methods**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [Copy Method] Marshal.Copy / Buffer.MemoryCopy               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   Managed Heap          memcpy           Native Heap        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ byte[]   â”‚      Data copied          â”‚ IntPtr   â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                             â”‚
â”‚   â†’ 2Ã— memory usage, copy time required                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [Zero-copy] fixed keyword                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   Managed Heap                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
â”‚  â”‚ byte[]   â”‚ â†â”€â”€ Pinned with fixed (GC cannot move)        â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                               â”‚
â”‚       â”‚                                                     â”‚
â”‚       â””â”€â”€â†’ Pointer directly passed to native code           â”‚
â”‚                                                             â”‚
â”‚   â†’ 1Ã— memory usage, zero copy time                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Practical Application**:
```csharp
// Read-only operations: Zero-copy Pinning
unsafe
{
    fixed (byte* ptr = managedArray)
    {
        NativeLib.Read(ptr, length); // No copying
    }
}

// Write operations: Copying required
IntPtr nativePtr = Marshal.AllocHGlobal(size);
Marshal.Copy(managedArray, 0, nativePtr, size);
NativeLib.Write(nativePtr, size);
Marshal.FreeHGlobal(nativePtr);
```

---

## Chapter 2: Java Native Memory Handling

Since JDK 14, Java has improved native memory management through the Foreign Memory API (now Foreign Function & Memory API). However, there's a critical constraint: **Heap arrays cannot be pinned**.

### 2.1 Arena-based Memory Allocation

**Test Environment**:
- Java: OpenJDK 22.0.2
- JMH 1.37
- OS: Ubuntu 24.04.3 LTS
- CPU: Intel Core Ultra 7 265K

| Arena Type | 64B | 1KB | 64KB | 1MB |
|-----------|-----|-----|------|-----|
| Confined (thread-local) | 42 ns | 47 ns | 887 ns | 13,400 ns |
| Shared (thread-safe) | 31,628 ns | 32,578 ns | 34,144 ns | 53,592 ns |
| Global (permanent) | 88 ns | 630 ns | 35,520 ns | 559,392 ns |
| Auto (automatic) | 482 ns | 818 ns | 37,572 ns | 635,644 ns |

**Key Insights**:

1. **Confined Arena** is fastest across all sizes because it's single-threaded only.
2. **Shared Arena** is very slow at approximately 31 Î¼s for small sizes due to synchronization overhead.
3. **For large sizes (1MB)**, all types show similar performance (approximately 13-635 Î¼s).

**Comparison with C#**:
- C# NativeMemory.Alloc: 61-63 Î¼s (size-independent)
- Java Confined Arena: 42 ns ~ 13.4 Î¼s (size-dependent)

Java is faster for small sizes, but performance drops dramatically when using Shared Arena for thread safety.

**Usage examples for each Arena type**:

```java
// 1. Confined Arena - Single thread only, fastest
try (Arena arena = Arena.ofConfined()) {
    MemorySegment segment = arena.allocate(1024);
    // Only usable in this thread
} // Automatically freed

// 2. Shared Arena - Thread-safe
try (Arena arena = Arena.ofShared()) {
    MemorySegment segment = arena.allocate(1024);
    // Shareable across threads
} // Automatically freed

// 3. Global Arena - Permanent allocation
MemorySegment segment = Arena.global().allocate(1024);
// Persists until process termination, cannot be freed

// 4. Auto Arena - GC-based automatic management
Arena arena = Arena.ofAuto();
MemorySegment segment = arena.allocate(1024);
// No close() needed, GC manages
```

**Arena type characteristics comparison**:

| Arena Type | Thread-Safe | Deallocation | Performance | Use Case |
|-----------|-------------|--------------|-------------|----------|
| `Confined` | âŒ Single thread | try-with-resources | ğŸš€ Fastest | Local operations |
| `Shared` | âœ… Multi-threaded | try-with-resources | ğŸ¢ Sync overhead | Cross-thread sharing |
| `Global` | âœ… Multi-threaded | Cannot free | âš¡ Fast | Constants, global data |
| `Auto` | âœ… Multi-threaded | GC automatic | ğŸ”„ GC dependent | Unclear lifetime |

**Java process memory structure**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      JVM Process Memory                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     Java Heap       â”‚           Native Memory               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ byte[] arrays     â”‚ â€¢ MemorySegment (Arena)               â”‚
â”‚ â€¢ Object instances  â”‚ â€¢ DirectByteBuffer internal buffer    â”‚
â”‚ â€¢ GC managed        â”‚ â€¢ JNI native allocation               â”‚
â”‚                     â”‚ â€¢ Released via Arena.close()          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  âš ï¸ Java cannot pin Heap arrays â†’ Copy mandatory for Native â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Java's Fundamental Constraint: Mandatory Heap â†’ Native Copying

Java cannot pin heap arrays. Therefore, **copying is mandatory for all heap data transfer to native**.

**Heap â†’ Native Copy Benchmark**:

| Method | 64B | 1KB | 64KB | 1MB |
|--------|-----|-----|------|-----|
| Heap â†’ MemorySegment Copy | 44 ns | 52 ns | 1,825 ns | 39,434 ns |
| Heap â†’ DirectBuffer Copy | 373 ns | 743 ns | 36,175 ns | 553,142 ns |
| Heap â†’ Native (reusable) | 2.5 ns | 8.4 ns | 1,390 ns | 25,074 ns |

**Key Insights**:

1. **Using reusable buffers** significantly reduces copy overhead (25 Î¼s at 1MB).
2. **DirectBuffer** is very slow when allocated each time (553 Î¼s at 1MB).
3. **MemorySegment** is generally faster than DirectBuffer.

**Decisive Difference from C#**:

```java
// Java: Copying mandatory
byte[] heapArray = new byte[1024];
try (Arena arena = Arena.ofConfined()) {
    MemorySegment segment = arena.allocate(1024);
    MemorySegment.copy(heapArray, 0, segment, ValueLayout.JAVA_BYTE, 0, 1024); // Copy occurs
    nativeProcess(segment);
}
```

```csharp
// C#: Zero-copy possible
byte[] managedArray = new byte[1024];
unsafe {
    fixed (byte* ptr = managedArray) {
        NativeProcess(ptr); // No copying
    }
}
```

### 2.3 DirectByteBuffer vs MemorySegment

**Allocation Performance**:

| Method | 64B | 1KB | 64KB | 1MB |
|--------|-----|-----|------|-----|
| DirectByteBuffer.allocate | 367 ns | 708 ns | 33,489 ns | 578,204 ns |
| MemorySegment.allocate | 43 ns | 50 ns | 930 ns | 13,480 ns |

**MemorySegment is 42Ã— faster than DirectByteBuffer** (at 1MB).

**Practical Guide**:
- Use MemorySegment instead of DirectByteBuffer unless working with legacy code
- Reuse Arena to minimize allocation overhead for frequent allocations

---

## Chapter 3: C# vs Java Direct Comparison

Now let's directly compare the performance of both languages. These results were measured in the same test environment.

### 3.1 Memory Allocation Performance Comparison

**64B Small Data Allocation**:

```
Fast â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Slow

Java Confined   â–ˆâ–ˆ 0.042 Î¼s
Java Global     â–ˆâ–ˆâ–ˆ 0.088 Î¼s
Java Auto       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 0.48 Î¼s
C# StackAlloc   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 11.7 Î¼s
Java Shared     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 31.6 Î¼s
C# NativeAlloc  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 63.6 Î¼s
C# Marshal      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 74.3 Î¼s
```

**1MB Large Data Allocation**:

```
Fast â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Slow

Java Confined   â–ˆâ–ˆ 13.4 Î¼s
Java Shared     â–ˆâ–ˆâ–ˆâ–ˆ 53.6 Î¼s
C# NativeAlloc  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 61.4 Î¼s
C# Marshal      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 86.3 Î¼s
C# StackAlloc   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 106.1 Î¼s
Java Global     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 559 Î¼s
Java Auto       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 636 Î¼s
```

| Size | C# Best Performance | Java Best Performance | Winner |
|------|--------------------|-----------------------|--------|
| 64B | StackAlloc (11.7 Î¼s) | Confined (0.042 Î¼s) | **Java 279Ã— faster** |
| 1KB | StackAlloc (12.1 Î¼s) | Confined (0.047 Î¼s) | **Java 257Ã— faster** |
| 64KB | StackAlloc (30.0 Î¼s) | Confined (0.89 Î¼s) | **Java 34Ã— faster** |
| 1MB | NativeAlloc (61.4 Î¼s) | Confined (13.4 Î¼s) | **Java 4.6Ã— faster** |

> **Insight**: Looking at allocation alone, Java's Confined Arena is overwhelmingly faster.
> However, this only compares "allocation" - actual native transfer requires additional copy costs.

### 3.2 Heap â†’ Native Data Transfer Performance Comparison

Comparing the total cost of transferring heap data to native code.

**64B Small Data Transfer**:

```
Fast â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Slow

Java Reusable    â–ˆ 0.0025 Î¼s (copy)
C# MemoryMarshal â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 4.2 Î¼s (Zero-copy)
C# Fixed         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 5.8 Î¼s (Zero-copy)
C# Marshal.Copy  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 11.2 Î¼s (copy)
Java Each Alloc  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 0.044 Î¼s (copy+alloc)
```

**1MB Large Data Transfer**:

```
Fast â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Slow

Java Reusable     â–ˆâ–ˆ 25.1 Î¼s (copy)
C# Fixed          â–ˆâ–ˆ 28.9 Î¼s (Zero-copy, pin only)
Java Each Alloc   â–ˆâ–ˆâ–ˆ 39.4 Î¼s (copy+alloc)
C# Marshal.Copy   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1,330 Î¼s (copy)
```

| Size | C# Zero-copy (Fixed) | Java Reusable Buffer Copy | Notes |
|------|---------------------|---------------------------|-------|
| 64B | 5.8 Î¼s | 0.0025 Î¼s | Java 2,320Ã— faster |
| 1KB | 5.8 Î¼s | 0.0084 Î¼s | Java 690Ã— faster |
| 64KB | 26.4 Î¼s | 1.39 Î¼s | Java 19Ã— faster |
| 1MB | 28.9 Î¼s | 25.1 Î¼s | **Nearly identical** |

> **Key Findings**:
> - **Small data (< 64KB)**: Java's reusable buffer copy is faster than C#'s Zero-copy!
> - **Large data (â‰¥ 1MB)**: Both languages show nearly identical performance.
> - C#'s `Marshal.Copy` is the slowest across all sizes.

### 3.3 Why These Results?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Performance Reversal Analysis                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  [Small Data < 64KB]                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ C# Fixed: GC pause + memory pinning overhead > actual copy cost  â”‚   â”‚
â”‚  â”‚ Java Copy: Only performs simple memcpy (very fast)               â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚ â†’ For small data, copying is faster than pinning!                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â”‚  [Large Data â‰¥ 1MB]                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ C# Fixed: Pinning overhead 28.9 Î¼s (size-independent)            â”‚   â”‚
â”‚  â”‚ Java Copy: memcpy 25.1 Î¼s (proportional to size)                 â”‚   â”‚
â”‚  â”‚                                                                   â”‚
â”‚  â”‚ â†’ As size grows, copy cost increases to match Zero-copy          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â”‚  [Conclusion]                                                           â”‚
â”‚  â€¢ Under 64KB: Java reusable buffer is more efficient                  â”‚
â”‚  â€¢ 1MB+: C# Zero-copy and Java copy perform equally                    â”‚
â”‚  â€¢ 10MB+: C# Zero-copy starts showing advantages                       â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.4 Practical Selection Guide (By Size)

| Data Size | Recommended Language/Method | Reason |
|-----------|----------------------------|--------|
| < 1KB | Java or C# | Performance difference negligible (< 10Î¼s) |
| 1KB ~ 64KB | Java (reusable buffer) | Copy faster than pin |
| 64KB ~ 1MB | Either works | Performance convergence zone |
| > 1MB | C# (Fixed) | Zero-copy advantage emerges |
| > 10MB | **C# (Fixed) strongly recommended** | Copy costs skyrocket |

---

## Chapter 4: Pin vs Copy - Architectural Differences

### 4.1 Architectural-Level Differences

| Feature | C# | Java |
|---------|-----|------|
| **Pinning Support** | âœ… `fixed`, `GCHandle` | âŒ Not possible |
| **Zero-copy Transfer** | âœ… Managed â†’ Native direct | âŒ Copying mandatory |
| **GC Impact** | Memory immovable during pinning | Independent of GC (copies) |
| **Performance** | Zero copy cost | Copy cost proportional to size |
| **Safety** | Requires unsafe blocks | Type-safe |

### 4.2 Performance Impact Comparison

**Actual benchmark results for transferring 1MB data to native**:

#### Send Operation (Read-only data transfer)

| Language | Method | Time | Notes |
|----------|--------|------|-------|
| C# | **Send_ZeroCopy (fixed)** | **112 Î¼s** | Pinning overhead only |
| Java | send_HeapCopyToNative (reusable) | 127 Î¼s | Copy + native call |
| C# | Send_WithCopy | 126 Î¼s | Copy + native call |
| Java | send_AllocateAndCopy (allocate each time) | 131 Î¼s | Allocate + copy + call |

**Analysis**:
- C#'s Zero-copy is fastest at **112 Î¼s**
- Java's reusable buffer copy at 127 Î¼s is nearly identical to C#'s With-copy (126 Î¼s)
- For 1MB data, **C# is approximately 13% faster** (with Zero-copy)

#### Transform Operation (Read-write data transformation)

| Language | Method | Time | Notes |
|----------|--------|------|-------|
| C# | **Transform_ZeroCopy (fixed)** | **20 Î¼s** | Pin only, in-place transformation |
| C# | Transform_WithCopy | 46 Î¼s | 2 copies (round-trip) |
| Java | transform_RoundTripCopy (reusable) | 65 Î¼s | 2 copies (round-trip) |
| Java | transform_AllocateAndRoundTrip | 80 Î¼s | Allocate + 2 copies |

**Analysis**:
- C#'s Zero-copy dominates at **20 Î¼s**
- Java's reusable buffer copy at 65 Î¼s is 1.4Ã— slower than C#'s With-copy (46 Î¼s)
- C# Zero-copy is **3.25Ã— faster** than Java's optimized copying

**Key Insights**:

1. **Send Operation (read-only)**: C# and Java difference is small (~13%)
2. **Transform Operation (read-write)**: C#'s Zero-copy has decisive advantage (3.25Ã— faster)
3. **Java's Constraint**: Cannot pin heap arrays, must copy
4. **C#'s Flexibility**: Can completely eliminate copy overhead with fixed keyword

### 4.3 Large Data Processing Scenario

**Scenario 1**: Send 1MB data to native 1,000 times (read-only)

| Language | Method | Total Time (Estimated) | Difference |
|----------|--------|------------------------|------------|
| C# | Send_ZeroCopy (fixed) | 112 ms | Baseline |
| Java | send_HeapCopyToNative (reusable) | 127 ms | +13% |
| C# | Send_WithCopy | 126 ms | +13% |

**Scenario 2**: Transform 1MB data 1,000 times (read-write)

| Language | Method | Total Time (Estimated) | Difference |
|----------|--------|------------------------|------------|
| C# | Transform_ZeroCopy (fixed) | 20 ms | Baseline (best performance) |
| C# | Transform_WithCopy | 46 ms | +130% |
| Java | transform_RoundTripCopy (reusable) | 65 ms | +225% |
| Java | transform_AllocateAndRoundTrip | 80 ms | +300% |

**Practical Implications**:
- **Read-only operations**: C# and Java difference is minimal (~13%)
- **Read-write operations**: C#'s Zero-copy has overwhelming advantage (3.25Ã— faster)
- **For in-place data transformation by native library**: strongly recommend C#'s fixed keyword
- For Java, buffer reuse is essential. Allocating each time is 57% slower.

---

## Chapter 5: Practical Application Guide

### 5.1 C# Native Memory Usage Patterns

**Pattern 1: Passing Read-only Data to Native**

```csharp
// Pass to native via Zero-copy
byte[] imageData = LoadImage();

unsafe
{
    fixed (byte* ptr = imageData)
    {
        ProcessImageNative(ptr, imageData.Length);
    }
}
```

**Use Cases**:
- Image/video processing (OpenCV, FFmpeg, etc.)
- Cryptography libraries (OpenSSL, etc.)
- Network packet processing

**Pattern 2: Writable Native Buffer**

```csharp
// Allocate native buffer with NativeMemory.Alloc
unsafe
{
    byte* nativeBuffer = (byte*)NativeMemory.Alloc(1024);

    try
    {
        FillDataNative(nativeBuffer, 1024);

        // Copy result to managed
        byte[] result = new byte[1024];
        fixed (byte* dest = result)
        {
            Buffer.MemoryCopy(nativeBuffer, dest, 1024, 1024);
        }
    }
    finally
    {
        NativeMemory.Free(nativeBuffer);
    }
}
```

**Pattern 3: High-performance I/O with Span**

```csharp
// Zero-copy read/write with Span
Span<byte> buffer = stackalloc byte[512];

int bytesRead = socket.Receive(buffer);

unsafe
{
    fixed (byte* ptr = buffer)
    {
        ProcessData(ptr, bytesRead);
    }
}
```

### 5.2 Java Native Memory Usage Patterns

**Pattern 1: Minimize Allocation by Reusing Arena**

```java
// Pre-create and reuse Arena
private final Arena arena = Arena.ofShared();
private final MemorySegment reusableBuffer =
    arena.allocate(1024 * 1024); // 1MB buffer

public void processData(byte[] heapData) {
    // Copy to reusable buffer
    MemorySegment.copy(heapData, 0,
        reusableBuffer, ValueLayout.JAVA_BYTE, 0, heapData.length);

    nativeProcess(reusableBuffer);
}

// On shutdown
public void close() {
    arena.close();
}
```

**Pattern 2: Streaming Data Processing**

```java
// Process in chunks for memory efficiency
try (Arena arena = Arena.ofConfined()) {
    MemorySegment chunk = arena.allocate(4096);

    while (hasMoreData()) {
        byte[] heapChunk = readChunk();
        MemorySegment.copy(heapChunk, 0, chunk, ValueLayout.JAVA_BYTE, 0, heapChunk.length);
        processChunk(chunk);
    }
}
```

**Pattern 3: DirectByteBuffer Legacy Code**

```java
// Integration with legacy NIO code
ByteBuffer directBuffer = ByteBuffer.allocateDirect(1024);
directBuffer.put(heapArray);
directBuffer.flip();

// Wrap as MemorySegment (Zero-copy)
MemorySegment segment = MemorySegment.ofBuffer(directBuffer);
nativeProcess(segment.address());
```

### 5.3 When to Choose Which Language

**Choose C# when**:

1. **Large read-only data processing**
   - Example: Processing 100MB images with native libraries
   - Reason: Zero-copy eliminates copy costs

2. **Frequent Managed â†” Native transitions**
   - Example: 10,000 native function calls per second
   - Reason: Minimal overhead with fixed keyword

3. **Memory efficiency is critical**
   - Example: IoT devices, embedded systems
   - Reason: Memory reuse without copying

**Choose Java when**:

1. **Safety is paramount**
   - Example: Financial systems, medical systems
   - Reason: Type-safe API without unsafe

2. **Cross-platform consistency**
   - Example: Identical code on Linux/macOS/Windows
   - Reason: JVM abstracts platform differences

3. **Small data processing**
   - Example: Frequent native calls with < 1KB data
   - Reason: Copy overhead is negligible (< 100ns)

---

## Conclusion

### Key Summary

1. **C#'s Strength: Zero-copy Pinning**
   - Direct transfer of managed arrays to native with `fixed` keyword
   - Zero copy cost for large data
   - Requires unsafe code

2. **Java's Constraint: Mandatory Copying**
   - Cannot pin heap arrays
   - All data must be copied to native
   - Overhead minimizable through Arena reuse

3. **Performance Differences**
   - Small sizes (< 1KB): Both languages similar (< 100ns difference)
   - Large sizes (> 64KB): C# Zero-copy advantage
   - Optimized Java copying is still fast enough (25Î¼s for 1MB)

4. **Practical Selection Criteria**
   - Read-only large data: C# advantage
   - Safety and type safety: Java advantage
   - Extreme performance optimization: C# advantage
   - Cross-platform consistency: Java advantage

### Final Recommendations

**For C# Developers**:
- Use `fixed` or `Span<T>` for Zero-copy when possible
- Small sizes: `stackalloc`, large sizes: `NativeMemory.Alloc`
- Use `Marshal.AllocHGlobal` only for legacy code

**For Java Developers**:
- Use MemorySegment instead of DirectByteBuffer unless legacy
- Reuse Arena to minimize allocation overhead
- Process large data in chunks for memory efficiency

Both languages provide modern and powerful native memory APIs. The key is understanding each language's characteristics and selecting the optimal pattern for your use case.

---

**Related Resources**:
- [C# NativeMemory API Documentation](https://learn.microsoft.com/en-us/dotnet/api/system.runtime.interopservices.nativememory)
- [Java Foreign Function & Memory API](https://openjdk.org/jeps/454)
- [Benchmark Source Code](https://github.com/ulala-x/ulala-x.github.io/tree/main/project/csharp-java-memory)
